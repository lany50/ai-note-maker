import streamlit as st
import openai
import re

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="AI å­¦ä¹ ç¬”è®°ç”Ÿæˆå™¨",
    page_icon="ğŸš€",
    layout="wide"
)


# --- AI å‡½æ•°å°è£… ---

def create_openai_client(api_key, base_url):
    """æ ¹æ®ç”¨æˆ·è¾“å…¥åˆ›å»º OpenAI å®¢æˆ·ç«¯"""
    return openai.OpenAI(
        api_key=api_key,
        base_url=base_url if base_url else "https://api.openai.com/v1"
    )


def generate_outline(client, model, temperature, chat_log):
    """ç¬¬ä¸€æ­¥ï¼šè°ƒç”¨ AI ç”Ÿæˆ Markdown å¤§çº²"""
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªéå¸¸ä¼˜ç§€çš„å­¦ä¹ ç¬”è®°æ€»ç»“åŠ©ç†ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯ï¼šé€šè¯»æˆ‘æä¾›çš„èŠå¤©è®°å½•å…¨æ–‡ï¼Œåˆ†æå‡ºå¯¹è¯çš„å†…åœ¨é€»è¾‘å’ŒçŸ¥è¯†ä½“ç³»ã€‚
    ç„¶åï¼Œè¯·ä»¥ Markdown æ ‡é¢˜çš„å½¢å¼ï¼ˆä¾‹å¦‚ `##` æˆ– `###`ï¼‰ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´çš„ã€å±‚çº§åˆ†æ˜çš„å­¦ä¹ ç¬”è®°å¤§çº²ã€‚
    ä½ ç”Ÿæˆçš„å›å¤ä¸­ï¼Œå¿…é¡»åªåŒ…å«è¿™ä¸ª Markdown æ ‡é¢˜å¤§çº²ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–è§£é‡Šæˆ–è¯´æ˜æ–‡å­—ã€‚
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": chat_log}
            ],
            temperature=temperature,
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"ç”Ÿæˆå¤§çº²å¤±è´¥ï¼š{e}")
        return None


def generate_details_streaming(client, model, temperature, chat_log, heading):
    """ç¬¬äºŒæ­¥ï¼šæ ¹æ®å•ä¸ªæ ‡é¢˜ï¼Œæµå¼ç”Ÿæˆè¯¦ç»†å†…å®¹"""
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„å­¦ä¹ ç¬”è®°ä¸“å®¶ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯ï¼šæ ¹æ®æˆ‘æä¾›çš„èŠå¤©è®°å½•å…¨æ–‡ï¼Œä»¥åŠä¸€ä¸ªç‰¹å®šçš„æ ‡é¢˜ï¼Œè¯¦ç»†æ€»ç»“å’Œé˜è¿°ä¸ã€Œ{heading}ã€è¿™ä¸ªæ ‡é¢˜ç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚
    è¯·ä½ åªè¾“å‡ºå’Œè¿™ä¸ªæ ‡é¢˜ç›´æ¥ç›¸å…³çš„å†…å®¹ï¼Œç¡®ä¿æ€»ç»“çš„ä¸“ä¸šã€è¯¦å°½ã€æ˜“äºç†è§£ã€‚
    è¯·ä½¿ç”¨ Markdown æ ¼å¼è¿›è¡Œè¾“å‡ºï¼Œå¯ä»¥åŒ…å«è¦ç‚¹ã€ä»£ç å—ã€å¼•ç”¨ç­‰ã€‚
    ä½ çš„è¾“å‡ºå°†ç›´æ¥ä½œä¸ºç¬”è®°å†…å®¹ï¼Œæ‰€ä»¥ä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„ã€ä¸ç¬”è®°å†…å®¹æ— å…³çš„è§£é‡Šï¼Œæ¯”å¦‚â€œå¥½çš„ï¼Œè¿™æ˜¯å…³äºxxxçš„æ€»ç»“ï¼šâ€ã€‚
    """
    try:
        stream = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": chat_log}  # å†æ¬¡æä¾›å…¨æ–‡ä½œä¸ºä¸Šä¸‹æ–‡
            ],
            temperature=temperature,
            stream=True,  # ï¼ï¼ï¼è¿™æ˜¯å®ç°æµå¼è¾“å‡ºçš„å…³é”®ï¼ï¼ï¼
        )
        for chunk in stream:
            # æ£€æŸ¥å—ä¸­æ˜¯å¦æœ‰å†…å®¹
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
    except Exception as e:
        st.error(f"ç”Ÿæˆã€Œ{heading}ã€çš„è¯¦ç»†å†…å®¹å¤±è´¥ï¼š{e}")


# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ”‘ API è®¾ç½®")
    base_url = st.text_input("API Base URL (å¯é€‰)")
    api_key = st.text_input("è¯·è¾“å…¥ä½ çš„ API Key", type="password")

    st.header("âš™ï¸ æ¨¡å‹é…ç½®")
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", ["pplx-claude-sonnet-4-20250514", "gemini-2.5-pro", "gpt-4.1"])
    temperature = st.slider("æ¸©åº¦ (Temperature)", min_value=0.0, max_value=1.0, value=0.7, step=0.1)

# --- ä¸»ç•Œé¢ ---
st.title("AI å­¦ä¹ ç¬”è®°ç”Ÿæˆå™¨ ğŸš€")

chat_log = st.text_area(
    "è¯·åœ¨æ­¤å¤„ç²˜è´´ä½ çš„èŠå¤©è®°å½•...",
    height=400,
    placeholder="ä¾‹å¦‚ï¼š\n\nç”¨æˆ·: ä½ å¥½ï¼Œè¯·å¸®æˆ‘è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯â€œæœºå™¨å­¦ä¹ â€ï¼Ÿ\nAI: æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯..."
)

if st.button("âœ¨ å¼€å§‹ç”Ÿæˆç¬”è®°", type="primary"):
    if not api_key:
        st.error("è¯·è¾“å…¥ä½ çš„ API Keyï¼")
    elif not chat_log:
        st.error("è¯·è¾“å…¥èŠå¤©è®°å½•ï¼")
    else:
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = create_openai_client(api_key, base_url)

        # --- ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå¤§çº² ---
        with st.spinner("ğŸ§  AI æ­£åœ¨ä¸ºä½ ç”Ÿæˆå¤§çº²..."):
            outline = generate_outline(client, selected_model, temperature, chat_log)

        if outline:
            st.success("å¤§çº²ç”Ÿæˆå®Œæ¯•ï¼å¼€å§‹å¡«å……è¯¦ç»†å†…å®¹...")

            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æå‡ºæ‰€æœ‰ Markdown æ ‡é¢˜
            headings = re.findall(r"^#+\s+(.*)", outline, re.MULTILINE)

            st.markdown("---")
            st.subheader("ğŸ“– æœ€ç»ˆå­¦ä¹ ç¬”è®°")

            # --- ç¬¬äºŒæ­¥ï¼šéå†å¤§çº²ï¼Œæµå¼å¡«å……ç»†èŠ‚ ---
            final_note = ""  # ç”¨äºç´¯åŠ æœ€ç»ˆç»“æœ
            for heading in headings:
                # é‡æ–°ç»„åˆæˆ Markdown æ ‡é¢˜æ ¼å¼å¹¶æ˜¾ç¤º
                full_heading = f"## {heading}"  # ä¸ºäº†ç»Ÿä¸€æ ¼å¼ï¼Œæˆ‘ä»¬éƒ½ç”¨äºŒçº§æ ‡é¢˜
                st.markdown(full_heading)
                final_note += full_heading + "\n\n"

                # ä½¿ç”¨ st.write_stream æ¥æ˜¾ç¤ºæµå¼å“åº”
                response_stream = generate_details_streaming(client, selected_model, temperature, chat_log, heading)

                # st.write_stream ä¼šè‡ªåŠ¨å¤„ç†ç”Ÿæˆå™¨ï¼Œå¹¶å°†å†…å®¹é€å—æ˜¾ç¤ºåœ¨é¡µé¢ä¸Š
                full_response = st.write_stream(response_stream)
                final_note += full_response + "\n\n"

            st.success("ğŸ‰ ç¬”è®°ç”Ÿæˆå®Œæ¯•ï¼")

            # æä¾›ä¸€ä¸ªä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç¬”è®° (Markdown)",
                data=final_note,
                file_name="å­¦ä¹ ç¬”è®°.md",
                mime="text/markdown",
            )